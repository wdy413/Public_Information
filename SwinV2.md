### 核心区别：全局注意力 vs. 窗口注意力



要理解复杂度，首先要明白两种模型计算“注意力”的范围不同。

1. **Vision Transformer (ViT) -> 全局注意力 (Global Self-Attention)** ViT 会把一张图片分割成 N 个图块 (Patch)，然后计算**每一个图块**与**其他所有图块**之间的关联性。这是一个“全局”的多对多关系。
2. **Swin Transformer -> 窗口注意力 (Window-based Self-Attention)** Swin Transformer 同样把图片分割成 N 个图块，但它并不会计算全局注意力。相反，它会先把这些图块划分成一个个不重叠的“窗口 (Window)”，然后只在**每个窗口内部**计算注意力。这是一个“局部”的多对多关系。

这个核心区别直接导致了它们计算复杂度的巨大差异。

------



### 数值举例：复杂度对比



我们假设处理一张 `224x224` 像素的输入图片，并分析 Self-Attention 这一步的计算量，因为这是 Transformer 模型中最耗费计算的部分。



#### 1. Vision Transformer (ViT) 的二次方复杂度 O(N2)



- **步骤1：切分图块 (Patch)**
  - ViT 通常使用 `16x16` 的 Patch。
  - 图片宽度上的图块数：`224 / 16 = 14` 个。
  - 图片高度上的图块数：`224 / 16 = 14` 个。
  - **总图块数 (Token 数) N** = `14 × 14 = 196` 个。
- **步骤2：计算注意力**
  - ViT 需要计算 196 个图块中，每个图块与其他所有 196 个图块（包括自身）的注意力得分。
  - 这会生成一个 `196 x 196` 的注意力矩阵。
  - **计算复杂度** proptoN2=1962=textbf38,416。
- **问题所在（二次方增长）**
  - 如果我们把图片分辨率提高一倍，变成 `448x448` 像素。
  - 总图块数 N' = `(448/16) × (448/16) = 28 × 28 = 784` 个。 (是原来的 **4倍**)
  - **新的计算复杂度** propto(N′)2=7842=614,656。
  - 我们发现，图块数 (像素面积) 增加了 4 倍，但计算量增加了 614,656/38,416=textbf16 **倍**！这就是典型的二次方 (O(N2)) 增长。

------



#### 2. Swin Transformer 的线性复杂度 O(N)



Swin Transformer 的设计巧妙地规避了上述问题。

- **步骤1：切分图块 (Patch)**
  - Swin 通常从更小的 `4x4` Patch 开始，以构建层次化特征。
  - 图片宽度上的图块数：`224 / 4 = 56` 个。
  - 图片高度上的图块数：`224 / 4 = 56` 个。
  - **总图块数 (Token 数) N** = `56 × 56 = 3136` 个。
- **步骤2：划分窗口 (Window)**
  - Swin 的默认**窗口大小 (Window Size)** 是 `7x7` 个图块。
  - 这意味着每个窗口里有 `7 × 7 = 49` 个图块。
- **步骤3：在窗口内计算注意力**
  - Swin **不会**去计算 `3136 x 3136` 的全局注意力。
  - 它只在每个小窗口内部计算注意力。对于一个窗口，计算量是固定的。
  - **单个窗口的计算复杂度** propto492=2,401。
  - **计算总共有多少个窗口**：整个特征图是 `56x56` 个图块，窗口大小是 `7x7`，所以总共有 `(56/7) × (56/7) = 8 × 8 = 64` 个窗口。
  - **总计算复杂度** = `(窗口数量) × (单个窗口的复杂度)` = 64times492=64times2,401=textbf153,664。
- **关键所在（线性增长）**
  - 让我们把上面的公式整理一下：总图块数 N=3136，窗口内的图块数 MtimesM=49。
  - 总复杂度 = (N/(M2))times(M2)2=NtimesM2。
  - 因为窗口大小 M2 是一个**固定不变的常数**（这里是 49），所以总复杂度**直接与总图块数 N 成正比**。这就是 **线性复杂度 O(N)** 的由来。
- **验证线性增长**
  - 同样，我们把图片分辨率提高一倍，变成 `448x448` 像素。
  - 新的总图块数 N' = `(448/4) × (448/4) = 112 × 112 = 12,544` 个。(是原来的 **4倍**)
  - **新的计算复杂度** = N′timesM2=12,544times49=614,656。
  - 我们发现，图块数 (像素面积) 增加了 4 倍，计算量也只增加了 614,656/153,664=textbf4 **倍**！

------



### 总结对比



| 特性                                | Vision Transformer (ViT) | Swin Transformer              |
| ----------------------------------- | ------------------------ | ----------------------------- |
| **注意力范围**                      | 全局 (Global)            | 窗口内 (Window-based)         |
| **复杂度公式**                      | O(N2) (N为图块数)        | O(NtimesM2) (M为固定窗口大小) |
| **复杂度类型**                      | **二次方**增长           | **线性**增长                  |
| **图片分辨率x2<br>(图块数N变为4N)** | 计算量增加 **16** 倍     | 计算量增加 **4** 倍           |

导出到 Google 表格

通过这个数值对比，可以清晰地看到，Swin Transformer 通过将计算限制在固定大小的窗口内，成功地将计算复杂度与图片像素数（或图块数）之间建立了一种线性关系，使其能够高效地处理高分辨率图像，而这正是 ViT 的主要瓶颈。
